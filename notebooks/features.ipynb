{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**02 • Features Builder (табличка/текст/гео/время/изображения)**\n\nЦель ноутбука — быстро собрать минимальный набор фич без CLI/YAML: всё управляется флагами `FAST`, `SAFE`, `USE_CACHE` прямо в ячейке параметров. Кэширование тяжёлых блоков (TF-IDF, geo-neighbors, эмбеддинги картинок) происходит в `artifacts/features/<block>/<key>/…`, чтобы можно было возобновлять прогон.\n\nМини-план тура: до обеда успеваем базовые числовые/категориальные, TF-IDF (если текст короткий), гео-гриды; тяжёлые шаги (BallTree-соседи, img-embeddings) — на перерыв или ночь.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ——— базовые импорты\nimport os, sys, json, math, time, gc, warnings\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\n\n# ——— прогресс/виджеты (но ноут должен работать и без них)\ntry:\n    from tqdm.auto import tqdm\nexcept Exception:\n    def tqdm(x, **kw): return x\n\ntry:\n    import ipywidgets as W\n    _WIDGETS = True\nexcept Exception:\n    _WIDGETS = False\n\n# ——— наш фич-слой\nfrom common.features import store, assemble\nfrom common.features import (\n    num_basic, cat_freq, cat_te_oof, text_tfidf,\n    geo_grid, geo_neighbors, time_agg,\n    crosses, img_index, img_stats, img_embed\n)\n\nfrom common.cache import make_key\npd.set_option(\"display.max_colwidth\", 120)\nwarnings.filterwarnings(\"ignore\")\n\n# ——— вспомогалки\ndef mem_gb(obj=None):\n    if obj is None:\n        import psutil\n        return psutil.Process().memory_info().rss / (1024**3)\n    if hasattr(obj, \"memory_usage\"):\n        try:\n            return obj.memory_usage(deep=True).sum()/(1024**3)\n        except Exception:\n            pass\n    return np.array(obj).nbytes/(1024**3)\n\ndef head(df, n=5):\n    display(df.head(n)); print(df.shape, \"mem:\", round(mem_gb(df), 3), \"GB\")\n\nprint(\"Widgets:\", _WIDGETS, \"| Python:\", sys.version)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Панель параметров — что задаём\n\n* Пути к данным и имена ключевых колонок.\n* Флаги `FAST` (урезает тяжёлые вещи), `SAFE` (жёсткие анти-утечки), `USE_CACHE`.\n* Списки `NUM_COLS`, `CAT_COLS`, `TEXT_COLS`, `MULTI_COLS` (можно оставить `None`, сработает авто-детект).\n* Чек-лист блоков, которые включаем/выключаем.\n* Ничего лишнего не сохраняется: только кэш фич-блоков. Финальный набор сохраняется отдельно флагом ниже.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ——— БАЗОВЫЕ ПАРАМЕТРЫ (редактируй здесь)\nDATA_DIR   = \"data\"            # можно папку\nTRAIN_PATH = f\"{DATA_DIR}/train.csv\"\nTEST_PATH  = f\"{DATA_DIR}/test.csv\"\n\nID_COL      = \"id\"\nTARGET_COL  = None             # если есть\nDATE_COL    = None\nLAT_COL     = None\nLON_COL     = None\nTEXT_COLS   = None             # например [\"text\"] или None\nMULTI_COLS  = None             # например [\"tags\"] или None\n\n# явные списки числовых/категориальных (можно оставить None, сделаем авто-детект)\nNUM_COLS = None\nCAT_COLS = None\n\n# глобальные флаги\nFAST      = True    # урезает \"тяжёлые\" параметры\nSAFE      = True    # максимально строгие анти-утечки\nUSE_CACHE = True    # использовать кэш артефактов фич-блоков\n\n# какой сплит (определится ниже): \"kfold\" | \"group\" | \"time\"\nSPLIT_KIND = \"kfold\"\nN_SPLITS   = 5\nGROUP_COL  = None      # например user_id/item_id для группового\nTIME_EMBARGO = None    # напр. \"2D\" | \"3h\" если нужно\n\n# какие блоки включить (по умолчанию базовый минимализм)\nACTIVE_BLOCKS = {\n    \"num_basic\": True,\n    \"cat_freq\": True,\n    \"cat_te_oof\": False,    # включай только если понимаешь анти-утечки\n    \"text_tfidf\": False,\n    \"geo_grid\": False,\n    \"geo_neighbors\": False,\n    \"time_agg\": False,\n    \"crosses\": False,\n    \"img_stats\": False,\n    \"img_embed\": False,     # тяжело; запускать на перерыве/ночью\n}\n\n# Сохранение итогового набора (опционально)\nSAVE_SET   = False\nRUN_TAG    = \"exp01\"\n\nif _WIDGETS:\n    # упрощённые виджеты: переключатели блоков/флагов\n    toggles = {k: W.Checkbox(value=v, description=k) for k, v in ACTIVE_BLOCKS.items()}\n    flags   = {\n        \"FAST\": W.Checkbox(value=FAST, description=\"FAST\"),\n        \"SAFE\": W.Checkbox(value=SAFE, description=\"SAFE\"),\n        \"USE_CACHE\": W.Checkbox(value=USE_CACHE, description=\"USE_CACHE\")\n    }\n    display(W.HBox(list(flags.values())))\n    display(W.GridBox(list(toggles.values()), layout=W.Layout(grid_template_columns=\"repeat(3, 220px)\")))\n    def _read_widgets():\n        global FAST, SAFE, USE_CACHE, ACTIVE_BLOCKS\n        FAST      = flags[\"FAST\"].value\n        SAFE      = flags[\"SAFE\"].value\n        USE_CACHE = flags[\"USE_CACHE\"].value\n        for k in ACTIVE_BLOCKS:\n            ACTIVE_BLOCKS[k] = toggles[k].value\n    display(W.Button(description=\"Применить флаги\", button_style=\"info\",\n                     tooltip=\"Считать значения чекбоксов\")).on_click(lambda _: _read_widgets())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Загрузка данных, авто-детект колонок, быстрый sanity-чек\n\n* Проверяем наличие колонок, NaN/константы, базовые типы.\n* Если `TEXT_COLS=None`, но текст в данных есть — задай список явно.\n* Выравниваем порядок столбцов между train/test.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ——— чтение\ntrain = pd.read_csv(TRAIN_PATH)\ntest  = pd.read_csv(TEST_PATH)\n\nprint(\"Train:\", train.shape, \"| Test:\", test.shape)\nassert ID_COL in train.columns and ID_COL in test.columns, \"ID_COL не найден\"\nif TARGET_COL:\n    assert TARGET_COL in train.columns, \"TARGET_COL не найден в train\"\n\n# ——— авто-детект типов\ndef auto_detect_columns(train, exclude):\n    num_cols, cat_cols, text_cols = [], [], []\n    for c in train.columns:\n        if c in exclude:\n            continue\n        if pd.api.types.is_numeric_dtype(train[c]):\n            num_cols.append(c)\n        elif pd.api.types.is_string_dtype(train[c]) and train[c].map(lambda x: isinstance(x, str) and len(x)>30).mean()>0.3:\n            text_cols.append(c)\n        else:\n            cat_cols.append(c)\n    return num_cols, cat_cols, text_cols\n\nif NUM_COLS is None or CAT_COLS is None or TEXT_COLS is None:\n    ex = {ID_COL} | ({TARGET_COL} if TARGET_COL else set())\n    n, c, t = auto_detect_columns(train, ex)\n    NUM_COLS = n if NUM_COLS is None else NUM_COLS\n    CAT_COLS = c if CAT_COLS is None else CAT_COLS\n    if TEXT_COLS is None and len(t)>0:\n        TEXT_COLS = t\n\nprint(\"NUM_COLS:\", NUM_COLS[:10] if NUM_COLS else [])\nprint(\"CAT_COLS:\", CAT_COLS[:10] if CAT_COLS else [])\nprint(\"TEXT_COLS:\", TEXT_COLS)\n\n# ——— базовая очистка: одинаковые столбцы, порядок\ntrain = train.copy(); test = test.copy()\ntrain_cols = [c for c in train.columns if c!=TARGET_COL]\ntest = test[train_cols]  # выравнивание\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Про сплиты и анти-утечки\n\n* Time-сплит: когда есть `DATE_COL` и прогнозируем будущее.\n* Group-сплит: если утечки возможны через пользователя/товар.\n* KFold по умолчанию, когда нет времени/групп.\n* Все обучаемые кодировки (TE/WOE/CTR) считаются строго по OOF.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n\ndef make_folds(train, task=\"binary\"):\n    idx = np.arange(len(train))\n    if SPLIT_KIND == \"time\" and DATE_COL:\n        # простой time-сплит: сортировка по времени и нарезка на N_SPLITS чанков\n        df = train.sort_values(DATE_COL).reset_index(drop=True)\n        fold_sizes = np.full(N_SPLITS, len(df)//N_SPLITS, dtype=int)\n        fold_sizes[:len(df)%N_SPLITS] += 1\n        cur = 0\n        folds = []\n        for k, fs in enumerate(fold_sizes):\n            val_idx = np.arange(cur, cur+fs)\n            tr_idx = np.setdiff1d(np.arange(len(df)), val_idx)\n            folds.append((df.index[tr_idx].to_numpy(), df.index[val_idx].to_numpy()))\n            cur += fs\n        return folds\n    elif SPLIT_KIND == \"group\" and GROUP_COL:\n        gkf = GroupKFold(n_splits=N_SPLITS)\n        return [(tr, va) for tr, va in gkf.split(idx, groups=train[GROUP_COL].values)]\n    else:\n        # по умолчанию — KFold (не stratified: у нас может быть регрессия/мульти)\n        kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n        return [(tr, va) for tr, va in kf.split(idx)]\n\nFOLDS = make_folds(train)\nprint(\"Folds:\", len(FOLDS), \"| fold sizes:\", [len(v) for _, v in FOLDS][:10])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Инициализация FeatureStore, соглашение о пакетах\n\n* Каждый блок возвращает `FeaturePackage(name, train, test, kind, cols, meta)`.\n* Имена колонок префиксуются, чтобы избегать конфликтов.\n* Кэш блоков включается флагом `use_cache=USE_CACHE`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "FS = store.FeatureStore()\nBUILT = []  # список имён пакетов в порядке построения\n\ndef run_block(name, fn, *args, _include=True, _params=None, **kwargs):\n    '''\n    Универсальная обёртка: печать параметров, тайминг, кэш, добавление в FS.\n    '''\n    if not _include:\n        print(f\"— SKIP {name}\")\n        return\n    t0 = time.time()\n    print(f\"\n=== BUILD {name} ===\")\n    if _params:\n        print(\"params:\", json.dumps(_params, ensure_ascii=False))\n    pkg = fn(*args, **kwargs)\n    FS.add(pkg)\n    BUILT.append(pkg.name)\n    dt = time.time() - t0\n    ntr = pkg.train.shape[1] if hasattr(pkg.train, \"shape\") else \"?\"\n    print(f\"done {name} in {dt:.1f}s | +{ntr} cols | kind={pkg.kind}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Числовые фичи (быстро и всегда полезно)\n\nИмпутация, лог-масштаб, клиппинг хвостов. Почти всегда включаем. В `FAST=True` оставляем простой набор без скейла/биннинга.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if ACTIVE_BLOCKS[\"num_basic\"] and NUM_COLS:\n    params = dict(prefix=\"num\", num_cols=NUM_COLS, log_cols=None, clip_quant=(0.01,0.99),\n                  impute=\"median\", scale=None, use_cache=USE_CACHE)\n    run_block(\"num_basic\", num_basic.build, train, test, _include=True, _params=params, **params)\nelse:\n    print(\"num_basic: пропущен (нет NUM_COLS или выключен)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Категориальные частоты (без утечек)\n\nСчитают частоты/доли без использования таргета — безопасный базовый сигнал для high-card категорий. Включаем почти всегда.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if ACTIVE_BLOCKS[\"cat_freq\"] and CAT_COLS:\n    params = dict(prefix=\"catf\", cat_cols=CAT_COLS, rare_threshold=0.01, use_cache=USE_CACHE)\n    run_block(\"cat_freq\", cat_freq.build, train, test, _params=params, **params)\nelse:\n    print(\"cat_freq: пропущен (нет CAT_COLS или выключен)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### OOF-кодировки (target/WOE/CTR) — опасно без OOF!\n\nВключаем только если понимаем анти-утечки и есть таргет. Всегда по `FOLDS`. В `FAST=True` чаще выключаем.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if ACTIVE_BLOCKS[\"cat_te_oof\"] and CAT_COLS and TARGET_COL:\n    params = dict(prefix=\"te\", cat_cols=CAT_COLS, method=\"target\", smoothing=\"m-estimate\", use_cache=USE_CACHE)\n    run_block(\"cat_te_oof\", cat_te_oof.build, train, train[TARGET_COL], test, FOLDS, _params=params, **params)\nelse:\n    print(\"cat_te_oof: пропущен (нет TARGET_COL/CAT_COLS или выключен)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Текстовые фичи (TF-IDF)\n\nЕсли есть текстовые поля: в `FAST=True` поднимаем `min_df`, убираем SVD. Sparse CSR отлично подходит для линейных моделей.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if ACTIVE_BLOCKS[\"text_tfidf\"] and TEXT_COLS:\n    # берём первый текстовый столбец (либо пробеги циклом)\n    text_col = TEXT_COLS[0]\n    params = dict(text_col=text_col, min_df=5 if FAST else 2, ngram_range=(1,2), use_char=False,\n                  svd_k=None if FAST else 256, prefix=\"tfidf\", use_cache=USE_CACHE)\n    run_block(\"text_tfidf\", text_tfidf.build, train, test, _params=params, **params)\nelse:\n    print(\"text_tfidf: пропущен (нет TEXT_COLS или выключен)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Гео — гриды и локальная плотность\n\nГриды по 300/1000 м дают хороший prior; соседи (BallTree) тяжелее. В `FAST=True` можно оставить только один крупный грид.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if ACTIVE_BLOCKS[\"geo_grid\"] and LAT_COL and LON_COL:\n    params = dict(lat_col=LAT_COL, lon_col=LON_COL,\n                  steps_m=(1000,) if FAST else (300,1000),\n                  prefix=\"geo\", use_cache=USE_CACHE)\n    run_block(\"geo_grid\", geo_grid.build, train, test, _params=params, **params)\nelse:\n    print(\"geo_grid: пропущен (нет LAT/LON или выключен)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if ACTIVE_BLOCKS[\"geo_neighbors\"] and LAT_COL and LON_COL:\n    params = dict(lat_col=LAT_COL, lon_col=LON_COL, radii_m=(1000,) if FAST else (300,1000),\n                  prefix=\"geonb\", use_cache=USE_CACHE)\n    run_block(\"geo_neighbors\", geo_neighbors.build, train, test, _params=params, **params)\nelse:\n    print(\"geo_neighbors: пропущен\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Время — лаги и роллинги (anti-leak)\n\nТолько для временных процессов и прогнозов в будущее. Всегда маска \"только прошлое\"; при необходимости — эмбарго.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if ACTIVE_BLOCKS[\"time_agg\"] and DATE_COL:\n    params = dict(date_col=DATE_COL, group_cols=[ID_COL], lags=(1,7), rollings=(7,30),\n                  folds=FOLDS if SAFE else None, prefix=\"time\", use_cache=USE_CACHE)\n    run_block(\"time_agg\", time_agg.build, train, _params=params, **params)\nelse:\n    print(\"time_agg: пропущен\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Взаимодействия (кресты)\n\nОграниченно: используем белый список, чтобы не взорвать размерность.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if ACTIVE_BLOCKS[\"crosses\"]:\n    params = dict(whitelist_num_pairs=None, whitelist_num_cat=None, prefix=\"x\", use_cache=USE_CACHE)\n    run_block(\"crosses\", crosses.build, train, test, _params=params, **params)\nelse:\n    print(\"crosses: пропущен\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Картинки — быстрые статистики vs эмбеддинги\n\n`img_stats` дешёв и может давать сигнал даже без DL; `img_embed` мощнее, но тяжелее и требует времени/железа. Запускай эмбеддинги на перерыве.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if ACTIVE_BLOCKS[\"img_stats\"]:\n    # нужно построить индекс id->список путей (пример — весь набор train+test)\n    all_ids = pd.concat([train[ID_COL], test[ID_COL]]).astype(str).unique()\n    try:\n        id2 = img_index.build_from_dir(Path(DATA_DIR)/\"images\", all_ids, pattern=\"{id}/*.jpg\", max_per_id=4)\n        params = dict(id_col=ID_COL, id_to_images=id2, prefix=\"imgstats\", use_cache=USE_CACHE)\n        run_block(\"img_stats\", img_stats.build, train, test, _params=params, **params)\n    except Exception as e:\n        print(\"img_stats: ошибка индекса или чтения:\", e)\nelse:\n    print(\"img_stats: пропущен\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if ACTIVE_BLOCKS[\"img_embed\"]:\n    all_ids = pd.concat([train[ID_COL], test[ID_COL]]).astype(str).unique()\n    try:\n        id2 = img_index.build_from_dir(Path(DATA_DIR)/\"images\", all_ids, pattern=\"{id}/*.jpg\", max_per_id=4)\n        params = dict(\n            id_col=ID_COL, id_to_images=id2,\n            backbone=\"resnet50\", image_size=224,\n            agg=\"mean\", pool=\"avg\", batch_size=64,\n            device=\"auto\", precision=\"auto\", dtype=\"float16\",\n            prefix=\"img\", use_cache=USE_CACHE\n        )\n        run_block(\"img_embed\", img_embed.build, train, test, _params=params, **params)\n    except Exception as e:\n        print(\"img_embed: пропущен —\", e)\nelse:\n    print(\"img_embed: пропущен\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Сборка матриц (Assembler) и паспорт фичей\n\nСобираем `X_dense` для деревьев и `X_sparse` для линейных моделей. Включаем пакеты по `kind`. \"Паспорт\" покажет, сколько фич добавил каждый блок и текущую память.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# разложим добавленные пакеты по типу\ndense_pkgs  = [name for name in FS.list() if FS.get(name).kind == \"dense\"]\nsparse_pkgs = [name for name in FS.list() if FS.get(name).kind == \"sparse\"]\n\nprint(\"DENSE packages:\", dense_pkgs)\nprint(\"SPARSE packages:\", sparse_pkgs)\n\nX_dense_tr, X_dense_te, catalog_dense = (None, None, None)\nX_sparse_tr, X_sparse_te, catalog_sparse = (None, None, None)\n\nif len(dense_pkgs):\n    X_dense_tr, X_dense_te, catalog_dense = assemble.make_dense(FS, include=dense_pkgs)\n    print(\"Dense shapes:\", X_dense_tr.shape, X_dense_te.shape, \"| mem:\", round(mem_gb(X_dense_tr), 3), \"GB\")\n\nif len(sparse_pkgs):\n    X_sparse_tr, X_sparse_te, catalog_sparse = assemble.make_sparse(FS, include=sparse_pkgs)\n    print(\"Sparse shapes:\", X_sparse_tr.shape, X_sparse_te.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Проверки перед сохранением\n\n* Совпадение столбцов train/test, отсутствие NaN/inf (для dense).\n* Число строк соответствует train/test.\n* Убедись, что размер набора подъёмный для твоей машины.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\nimport joblib, pickle, json\n\ndef save_set(run_tag, Xd_tr, Xd_te, Xs_tr, Xs_te, y=None, folds=None, catalog=None):\n    base = Path(\"artifacts/sets\")/run_tag\n    base.mkdir(parents=True, exist_ok=True)\n    if Xd_tr is not None:\n        Xd_tr.to_parquet(base/\"X_dense_train.parquet\")\n        Xd_te.to_parquet(base/\"X_dense_test.parquet\")\n    if Xs_tr is not None:\n        from scipy import sparse\n        sparse.save_npz(base/\"X_sparse_train.npz\", Xs_tr)\n        sparse.save_npz(base/\"X_sparse_test.npz\", Xs_te)\n    meta = {\"catalog\": catalog, \"rows_train\": len(train), \"rows_test\": len(test), \"built\": BUILT}\n    (base/\"meta.json\").write_text(json.dumps(meta, ensure_ascii=False, indent=2))\n    print(\"Saved to:\", base)\n\nif SAVE_SET:\n    cat_merged = catalog_dense or catalog_sparse\n    save_set(RUN_TAG, X_dense_tr, X_dense_te, X_sparse_tr, X_sparse_te, catalog=cat_merged)\nelse:\n    print(\"Сохранение набора выключено (SAVE_SET=False)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Что дальше\n\n* Открой `notebooks/03_model.ipynb` для обучения модели.\n* Если сохранял набор — в `03_model` можно читать его с диска; иначе используй переменные из текущего kernel.\n* Шпаргалка: мало времени → только `num_basic` + `cat_freq`; быстрый сильный бейзлайн — TF-IDF + линейная модель; тяжёлые `geo_neighbors` и `img_embed` запускай на перерыве.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}